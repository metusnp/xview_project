{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ab978664659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbbox_iou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import numpy as np\n",
    "import six\n",
    "\n",
    "from model.utils.bbox_tools import bbox_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_detection_voc(\n",
    "        pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels,\n",
    "        gt_difficults=None,\n",
    "        iou_thresh=0.5, use_07_metric=False):\n",
    "    \"\"\"Calculate average precisions based on evaluation code of PASCAL VOC.\n",
    "    This function evaluates predicted bounding boxes obtained from a dataset\n",
    "    which has :math:`N` images by using average precision for each class.\n",
    "    The code is based on the evaluation code used in PASCAL VOC Challenge.\n",
    "    Args:\n",
    "        pred_bboxes (iterable of numpy.ndarray): An iterable of :math:`N`\n",
    "            sets of bounding boxes.\n",
    "            Its index corresponds to an index for the base dataset.\n",
    "            Each element of :obj:`pred_bboxes` is a set of coordinates\n",
    "            of bounding boxes. This is an array whose shape is :math:`(R, 4)`,\n",
    "            where :math:`R` corresponds\n",
    "            to the number of bounding boxes, which may vary among boxes.\n",
    "            The second axis corresponds to\n",
    "            :math:`y_{min}, x_{min}, y_{max}, x_{max}` of a bounding box.\n",
    "        pred_labels (iterable of numpy.ndarray): An iterable of labels.\n",
    "            Similar to :obj:`pred_bboxes`, its index corresponds to an\n",
    "            index for the base dataset. Its length is :math:`N`.\n",
    "        pred_scores (iterable of numpy.ndarray): An iterable of confidence\n",
    "            scores for predicted bounding boxes. Similar to :obj:`pred_bboxes`,\n",
    "            its index corresponds to an index for the base dataset.\n",
    "            Its length is :math:`N`.\n",
    "        gt_bboxes (iterable of numpy.ndarray): An iterable of ground truth\n",
    "            bounding boxes\n",
    "            whose length is :math:`N`. An element of :obj:`gt_bboxes` is a\n",
    "            bounding box whose shape is :math:`(R, 4)`. Note that the number of\n",
    "            bounding boxes in each image does not need to be same as the number\n",
    "            of corresponding predicted boxes.\n",
    "        gt_labels (iterable of numpy.ndarray): An iterable of ground truth\n",
    "            labels which are organized similarly to :obj:`gt_bboxes`.\n",
    "        gt_difficults (iterable of numpy.ndarray): An iterable of boolean\n",
    "            arrays which is organized similarly to :obj:`gt_bboxes`.\n",
    "            This tells whether the\n",
    "            corresponding ground truth bounding box is difficult or not.\n",
    "            By default, this is :obj:`None`. In that case, this function\n",
    "            considers all bounding boxes to be not difficult.\n",
    "        iou_thresh (float): A prediction is correct if its Intersection over\n",
    "            Union with the ground truth is above this value.\n",
    "        use_07_metric (bool): Whether to use PASCAL VOC 2007 evaluation metric\n",
    "            for calculating average precision. The default value is\n",
    "            :obj:`False`.\n",
    "    Returns:\n",
    "        dict:\n",
    "        The keys, value-types and the description of the values are listed\n",
    "        below.\n",
    "        * **ap** (*numpy.ndarray*): An array of average precisions. \\\n",
    "            The :math:`l`-th value corresponds to the average precision \\\n",
    "            for class :math:`l`. If class :math:`l` does not exist in \\\n",
    "            either :obj:`pred_labels` or :obj:`gt_labels`, the corresponding \\\n",
    "            value is set to :obj:`numpy.nan`.\n",
    "        * **map** (*float*): The average of Average Precisions over classes.\n",
    "    \"\"\"\n",
    "\n",
    "    prec, rec = calc_detection_voc_prec_rec(\n",
    "        pred_bboxes, pred_labels, pred_scores,\n",
    "        gt_bboxes, gt_labels, gt_difficults,\n",
    "        iou_thresh=iou_thresh)\n",
    "\n",
    "    ap = calc_detection_voc_ap(prec, rec, use_07_metric=use_07_metric)\n",
    "\n",
    "    return {'ap': ap, 'map': np.nanmean(ap)}\n",
    "\n",
    "\n",
    "def calc_detection_voc_prec_rec(\n",
    "        pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels,\n",
    "        gt_difficults=None,\n",
    "        iou_thresh=0.5):\n",
    "    \"\"\"Calculate precision and recall based on evaluation code of PASCAL VOC.\n",
    "    This function calculates precision and recall of\n",
    "    predicted bounding boxes obtained from a dataset which has :math:`N`\n",
    "    images.\n",
    "    The code is based on the evaluation code used in PASCAL VOC Challenge.\n",
    "    Args:\n",
    "        pred_bboxes (iterable of numpy.ndarray): An iterable of :math:`N`\n",
    "            sets of bounding boxes.\n",
    "            Its index corresponds to an index for the base dataset.\n",
    "            Each element of :obj:`pred_bboxes` is a set of coordinates\n",
    "            of bounding boxes. This is an array whose shape is :math:`(R, 4)`,\n",
    "            where :math:`R` corresponds\n",
    "            to the number of bounding boxes, which may vary among boxes.\n",
    "            The second axis corresponds to\n",
    "            :math:`y_{min}, x_{min}, y_{max}, x_{max}` of a bounding box.\n",
    "        pred_labels (iterable of numpy.ndarray): An iterable of labels.\n",
    "            Similar to :obj:`pred_bboxes`, its index corresponds to an\n",
    "            index for the base dataset. Its length is :math:`N`.\n",
    "        pred_scores (iterable of numpy.ndarray): An iterable of confidence\n",
    "            scores for predicted bounding boxes. Similar to :obj:`pred_bboxes`,\n",
    "            its index corresponds to an index for the base dataset.\n",
    "            Its length is :math:`N`.\n",
    "        gt_bboxes (iterable of numpy.ndarray): An iterable of ground truth\n",
    "            bounding boxes\n",
    "            whose length is :math:`N`. An element of :obj:`gt_bboxes` is a\n",
    "            bounding box whose shape is :math:`(R, 4)`. Note that the number of\n",
    "            bounding boxes in each image does not need to be same as the number\n",
    "            of corresponding predicted boxes.\n",
    "        gt_labels (iterable of numpy.ndarray): An iterable of ground truth\n",
    "            labels which are organized similarly to :obj:`gt_bboxes`.\n",
    "        gt_difficults (iterable of numpy.ndarray): An iterable of boolean\n",
    "            arrays which is organized similarly to :obj:`gt_bboxes`.\n",
    "            This tells whether the\n",
    "            corresponding ground truth bounding box is difficult or not.\n",
    "            By default, this is :obj:`None`. In that case, this function\n",
    "            considers all bounding boxes to be not difficult.\n",
    "        iou_thresh (float): A prediction is correct if its Intersection over\n",
    "            Union with the ground truth is above this value..\n",
    "    Returns:\n",
    "        tuple of two lists:\n",
    "        This function returns two lists: :obj:`prec` and :obj:`rec`.\n",
    "        * :obj:`prec`: A list of arrays. :obj:`prec[l]` is precision \\\n",
    "            for class :math:`l`. If class :math:`l` does not exist in \\\n",
    "            either :obj:`pred_labels` or :obj:`gt_labels`, :obj:`prec[l]` is \\\n",
    "            set to :obj:`None`.\n",
    "        * :obj:`rec`: A list of arrays. :obj:`rec[l]` is recall \\\n",
    "            for class :math:`l`. If class :math:`l` that is not marked as \\\n",
    "            difficult does not exist in \\\n",
    "            :obj:`gt_labels`, :obj:`rec[l]` is \\\n",
    "            set to :obj:`None`.\n",
    "    \"\"\"\n",
    "\n",
    "    pred_bboxes = iter(pred_bboxes)\n",
    "    pred_labels = iter(pred_labels)\n",
    "    pred_scores = iter(pred_scores)\n",
    "    gt_bboxes = iter(gt_bboxes)\n",
    "    gt_labels = iter(gt_labels)\n",
    "    if gt_difficults is None:\n",
    "        gt_difficults = itertools.repeat(None)\n",
    "    else:\n",
    "        gt_difficults = iter(gt_difficults)\n",
    "\n",
    "    n_pos = defaultdict(int)\n",
    "    score = defaultdict(list)\n",
    "    match = defaultdict(list)\n",
    "\n",
    "    for pred_bbox, pred_label, pred_score, gt_bbox, gt_label, gt_difficult in \\\n",
    "            six.moves.zip(\n",
    "                pred_bboxes, pred_labels, pred_scores,\n",
    "                gt_bboxes, gt_labels, gt_difficults):\n",
    "\n",
    "        if gt_difficult is None:\n",
    "            gt_difficult = np.zeros(gt_bbox.shape[0], dtype=bool)\n",
    "\n",
    "        for l in np.unique(np.concatenate((pred_label, gt_label)).astype(int)):\n",
    "            pred_mask_l = pred_label == l\n",
    "            pred_bbox_l = pred_bbox[pred_mask_l]\n",
    "            pred_score_l = pred_score[pred_mask_l]\n",
    "            # sort by score\n",
    "            order = pred_score_l.argsort()[::-1]\n",
    "            pred_bbox_l = pred_bbox_l[order]\n",
    "            pred_score_l = pred_score_l[order]\n",
    "\n",
    "            gt_mask_l = gt_label == l\n",
    "            gt_bbox_l = gt_bbox[gt_mask_l]\n",
    "            gt_difficult_l = gt_difficult[gt_mask_l]\n",
    "\n",
    "            n_pos[l] += np.logical_not(gt_difficult_l).sum()\n",
    "            score[l].extend(pred_score_l)\n",
    "\n",
    "            if len(pred_bbox_l) == 0:\n",
    "                continue\n",
    "            if len(gt_bbox_l) == 0:\n",
    "                match[l].extend((0,) * pred_bbox_l.shape[0])\n",
    "                continue\n",
    "\n",
    "            # VOC evaluation follows integer typed bounding boxes.\n",
    "            pred_bbox_l = pred_bbox_l.copy()\n",
    "            pred_bbox_l[:, 2:] += 1\n",
    "            gt_bbox_l = gt_bbox_l.copy()\n",
    "            gt_bbox_l[:, 2:] += 1\n",
    "\n",
    "            iou = bbox_iou(pred_bbox_l, gt_bbox_l)\n",
    "            gt_index = iou.argmax(axis=1)\n",
    "            # set -1 if there is no matching ground truth\n",
    "            gt_index[iou.max(axis=1) < iou_thresh] = -1\n",
    "            del iou\n",
    "\n",
    "            selec = np.zeros(gt_bbox_l.shape[0], dtype=bool)\n",
    "            for gt_idx in gt_index:\n",
    "                if gt_idx >= 0:\n",
    "                    if gt_difficult_l[gt_idx]:\n",
    "                        match[l].append(-1)\n",
    "                    else:\n",
    "                        if not selec[gt_idx]:\n",
    "                            match[l].append(1)\n",
    "                        else:\n",
    "                            match[l].append(0)\n",
    "                    selec[gt_idx] = True\n",
    "                else:\n",
    "                    match[l].append(0)\n",
    "\n",
    "    for iter_ in (\n",
    "            pred_bboxes, pred_labels, pred_scores,\n",
    "            gt_bboxes, gt_labels, gt_difficults):\n",
    "        if next(iter_, None) is not None:\n",
    "            raise ValueError('Length of input iterables need to be same.')\n",
    "\n",
    "    n_fg_class = max(n_pos.keys()) + 1\n",
    "    prec = [None] * n_fg_class\n",
    "    rec = [None] * n_fg_class\n",
    "\n",
    "    for l in n_pos.keys():\n",
    "        score_l = np.array(score[l])\n",
    "        match_l = np.array(match[l], dtype=np.int8)\n",
    "\n",
    "        order = score_l.argsort()[::-1]\n",
    "        match_l = match_l[order]\n",
    "\n",
    "        tp = np.cumsum(match_l == 1)\n",
    "        fp = np.cumsum(match_l == 0)\n",
    "\n",
    "        # If an element of fp + tp is 0,\n",
    "        # the corresponding element of prec[l] is nan.\n",
    "        prec[l] = tp / (fp + tp)\n",
    "        # If n_pos[l] is 0, rec[l] is None.\n",
    "        if n_pos[l] > 0:\n",
    "            rec[l] = tp / n_pos[l]\n",
    "\n",
    "    return prec, rec\n",
    "\n",
    "\n",
    "def calc_detection_voc_ap(prec, rec, use_07_metric=False):\n",
    "    \"\"\"Calculate average precisions based on evaluation code of PASCAL VOC.\n",
    "    This function calculates average precisions\n",
    "    from given precisions and recalls.\n",
    "    The code is based on the evaluation code used in PASCAL VOC Challenge.\n",
    "    Args:\n",
    "        prec (list of numpy.array): A list of arrays.\n",
    "            :obj:`prec[l]` indicates precision for class :math:`l`.\n",
    "            If :obj:`prec[l]` is :obj:`None`, this function returns\n",
    "            :obj:`numpy.nan` for class :math:`l`.\n",
    "        rec (list of numpy.array): A list of arrays.\n",
    "            :obj:`rec[l]` indicates recall for class :math:`l`.\n",
    "            If :obj:`rec[l]` is :obj:`None`, this function returns\n",
    "            :obj:`numpy.nan` for class :math:`l`.\n",
    "        use_07_metric (bool): Whether to use PASCAL VOC 2007 evaluation metric\n",
    "            for calculating average precision. The default value is\n",
    "            :obj:`False`.\n",
    "    Returns:\n",
    "        ~numpy.ndarray:\n",
    "        This function returns an array of average precisions.\n",
    "        The :math:`l`-th value corresponds to the average precision\n",
    "        for class :math:`l`. If :obj:`prec[l]` or :obj:`rec[l]` is\n",
    "        :obj:`None`, the corresponding value is set to :obj:`numpy.nan`.\n",
    "    \"\"\"\n",
    "\n",
    "    n_fg_class = len(prec)\n",
    "    ap = np.empty(n_fg_class)\n",
    "    for l in six.moves.range(n_fg_class):\n",
    "        if prec[l] is None or rec[l] is None:\n",
    "            ap[l] = np.nan\n",
    "            continue\n",
    "\n",
    "        if use_07_metric:\n",
    "            # 11 point metric\n",
    "            ap[l] = 0\n",
    "            for t in np.arange(0., 1.1, 0.1):\n",
    "                if np.sum(rec[l] >= t) == 0:\n",
    "                    p = 0\n",
    "                else:\n",
    "                    p = np.max(np.nan_to_num(prec[l])[rec[l] >= t])\n",
    "                ap[l] += p / 11\n",
    "        else:\n",
    "            # correct AP calculation\n",
    "            # first append sentinel values at the end\n",
    "            mpre = np.concatenate(([0], np.nan_to_num(prec[l]), [0]))\n",
    "            mrec = np.concatenate(([0], rec[l], [1]))\n",
    "\n",
    "            mpre = np.maximum.accumulate(mpre[::-1])[::-1]\n",
    "\n",
    "            # to calculate area under PR curve, look for points\n",
    "            # where X axis (recall) changes value\n",
    "            i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "            # and sum (\\Delta recall) * prec\n",
    "            ap[l] = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "\n",
    "    return ap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
